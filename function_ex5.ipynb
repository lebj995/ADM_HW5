{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_modularity(adj_list, communities, m):\n",
    "    \"\"\"Calculate the weighted modularity of the graph.\"\"\"\n",
    "    Q = 0.0\n",
    "    for node in adj_list:\n",
    "        for neighbor, weight in adj_list[node].items():\n",
    "            if communities[node] == communities[neighbor]:  # Check if nodes are in the same community\n",
    "                ki = sum(adj_list[node].values())  # Weighted degree of the node\n",
    "                kj = sum(adj_list[neighbor].values())  # Weighted degree of the neighbor\n",
    "                Q += weight - (ki * kj) / (2 * m)  # Modularity formula\n",
    "    return Q / (2 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain_with_max_iterations(adj_list, max_iterations=600, print_limit=5):\n",
    "    \"\"\"Louvain algorithm with a maximum number of iterations.\"\"\"\n",
    "    # Initialize each node in a separate community\n",
    "    communities = {node: i for i, node in enumerate(adj_list)}\n",
    "    m = sum(sum(neighbors.values()) for neighbors in adj_list.values()) / 2  # Total weight of the graph\n",
    "\n",
    "    print(f\"Total nodes: {len(adj_list)}, Total graph weight (2m): {2 * m}\")\n",
    "\n",
    "    improvement = True\n",
    "    iteration = 0\n",
    "    modularity_history = []  # Track modularity improvements for debugging and analysis\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        improvement = False  # Reset improvement flag for this iteration\n",
    "        nodes = list(adj_list.keys())\n",
    "        random.shuffle(nodes)  # Shuffle the nodes to process them in a random order\n",
    "\n",
    "        # Print only the first and last iterations based on the limit\n",
    "        if iteration <= print_limit or iteration > max_iterations - print_limit:\n",
    "            print(f\"\\nIteration {iteration} - Nodes: {len(nodes)}\")\n",
    "\n",
    "        for node in nodes:\n",
    "            best_community = communities[node]  # Initialize with the current community\n",
    "            best_increase = 0  # Initialize the best modularity increase as zero\n",
    "            current_community = communities[node]  # Store the current community of the node\n",
    "\n",
    "            # Compute the sum of weights for each neighboring community\n",
    "            neighbor_communities = defaultdict(float)\n",
    "            for neighbor, weight in adj_list[node].items():\n",
    "                neighbor_communities[communities[neighbor]] += weight\n",
    "\n",
    "            # Evaluate modularity gain for moving the node to each neighboring community\n",
    "            for community, weight_sum in neighbor_communities.items():\n",
    "                ki = sum(adj_list[node].values())  # Weighted degree of the node\n",
    "                sigma_tot = sum(sum(adj_list[n].values()) for n in adj_list if communities[n] == community)\n",
    "                delta_Q = (weight_sum - (ki * sigma_tot) / (2 * m))  # Modularity gain formula\n",
    "\n",
    "                if delta_Q > best_increase:  # Check if this move improves modularity\n",
    "                    best_community = community\n",
    "                    best_increase = delta_Q\n",
    "\n",
    "            # Update the community of the node if a better one was found\n",
    "            if best_community != current_community:\n",
    "                communities[node] = best_community\n",
    "                improvement = True\n",
    "\n",
    "        # Compute the modularity after the current iteration\n",
    "        current_modularity = compute_modularity(adj_list, communities, m)\n",
    "        modularity_history.append(current_modularity)  # Store modularity for analysis\n",
    "\n",
    "        # Print only the first and last iterations based on the limit\n",
    "        if iteration <= print_limit or iteration > max_iterations - print_limit:\n",
    "            print(f\"Iteration {iteration} - Modularity: {current_modularity:.6f}\")\n",
    "            print(f\"Elapsed time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_communities(communities):\n",
    "    \"\"\"\n",
    "    Print all detected communities.\n",
    "    \"\"\"\n",
    "    print(f\"Total number of detected communities: {len(communities)}\")\n",
    "    for i, community in enumerate(communities):\n",
    "        print(f\"Community {i+1} ({len(community)} nodes):\")\n",
    "        print(\", \".join(community))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cities_communities(city_communities, city1, city2):\n",
    "    \"\"\"\n",
    "    Analyze communities to check if two cities belong to the same community.\n",
    "\n",
    "    Input:\n",
    "        - city_communities: List of communities (of cities)\n",
    "        - city1: Name of the first city\n",
    "        - city2: Name of the second city\n",
    "\n",
    "    Output:\n",
    "        - Indicates whether city1 and city2 belong to the same community\n",
    "    \"\"\"\n",
    "    for i, community in enumerate(city_communities):\n",
    "        if city1 in community and city2 in community:\n",
    "            print(f\"{city1} and {city2} belong to the same community ({i + 1}).\")\n",
    "            return\n",
    "    print(f\"{city1} and {city2} do not belong to the same community.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_community_statistics(df, communities):\n",
    "    \"\"\"Analyze statistics for the first 5 communities.\"\"\"\n",
    "    for i, community in enumerate(communities[:5]):  # Limit to the first 5 communities\n",
    "        # Filter the DataFrame for nodes in the community\n",
    "        community_df = df[df['Origin_airport'].isin(community) & df['Destination_airport'].isin(community)]\n",
    "\n",
    "        # Calculate aggregated statistics\n",
    "        total_flights = community_df['Flights'].sum()\n",
    "        total_passengers = community_df['Passengers'].sum()\n",
    "        avg_distance = community_df['Distance'].mean()\n",
    "\n",
    "        # Print statistics for the community\n",
    "        print(f\"Community {i+1}:\")\n",
    "        print(f\"  Number of nodes: {len(community)}\")\n",
    "        print(f\"  Total flights: {total_flights}\")\n",
    "        print(f\"  Total passengers: {total_passengers}\")\n",
    "        print(f\"  Average distance: {avg_distance:.2f} km\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_geographic_distribution(df, communities):\n",
    "    \"\"\"Analyze the geographic distribution of the community.\"\"\"\n",
    "    for i, community in enumerate(communities):\n",
    "        # Filter the DataFrame for nodes in the community\n",
    "        community_df = df[df['Origin_airport'].isin(community)]\n",
    "\n",
    "        # Get the cities and their counts\n",
    "        cities = community_df['Origin_city'].value_counts()\n",
    "\n",
    "        print(f\"Community {i+1}:\")\n",
    "        print(f\"  Top cities (by frequency):\")\n",
    "        print(cities.head(5))  # Display the top 5 cities\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation_weighted(adj_list_weighted):\n",
    "    \"\"\"\n",
    "    Manual implementation of Label Propagation on a weighted graph.\n",
    "\n",
    "    Input:\n",
    "        - adj_list_weighted: Weighted adjacency dictionary {node: {neighbor: weight, ...}}\n",
    "    Output:\n",
    "        - communities: List of communities (each community is a list of nodes)\n",
    "    \"\"\"\n",
    "    # 1. Initialize each node with a unique label\n",
    "    labels = {node: node for node in adj_list_weighted}\n",
    "\n",
    "    # 2. Iterate until convergence\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        converged = True\n",
    "        nodes = list(adj_list_weighted.keys())\n",
    "        random.shuffle(nodes)  # Random order of nodes\n",
    "\n",
    "        for node in nodes:\n",
    "            # Count weighted labels of neighbors\n",
    "            neighbor_labels = {}\n",
    "            for neighbor, weight in adj_list_weighted[node].items():\n",
    "                label = labels[neighbor]\n",
    "                if label not in neighbor_labels:\n",
    "                    neighbor_labels[label] = 0\n",
    "                neighbor_labels[label] += weight  # Sum of weights per label\n",
    "\n",
    "            # Find the label with the maximum weight\n",
    "            if neighbor_labels:\n",
    "                new_label = max(neighbor_labels, key=neighbor_labels.get)\n",
    "\n",
    "                # If the label changes, update and continue the iteration\n",
    "                if labels[node] != new_label:\n",
    "                    labels[node] = new_label\n",
    "                    converged = False\n",
    "\n",
    "    # 3. Group nodes by label\n",
    "    communities = {}\n",
    "    for node, label in labels.items():\n",
    "        if label not in communities:\n",
    "            communities[label] = []\n",
    "        communities[label].append(node)\n",
    "\n",
    "    return list(communities.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_communities_stats(communities, method_name):\n",
    "    sizes = [len(community) for community in communities]\n",
    "    print(f\"\\n[{method_name}]\")\n",
    "    print(f\"Number of communities: {len(communities)}\")\n",
    "    print(f\"Minimum community size: {min(sizes)}\")\n",
    "    print(f\"Maximum community size: {max(sizes)}\")\n",
    "    print(f\"Average community size: {sum(sizes) / len(sizes):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_modularity(graph, communities):\n",
    "    \"\"\"\n",
    "    Calculate the modularity of the communities.\n",
    "    \"\"\"\n",
    "    m = sum(sum(weights.values()) for weights in graph.values()) / 2  # Sum of weights\n",
    "    modularity = 0\n",
    "    for community in communities:\n",
    "        for node_i in community:\n",
    "            for node_j in community:\n",
    "                weight = graph[node_i].get(node_j, 0)\n",
    "                degree_i = sum(graph[node_i].values())\n",
    "                degree_j = sum(graph[node_j].values())\n",
    "                modularity += (weight - (degree_i * degree_j) / (2 * m))\n",
    "    return modularity / (2 * m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
